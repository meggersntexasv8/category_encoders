

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Hashing &mdash; Category Encoders latest documentation</title>
  

  
  
  
  

  
  <script type="text/javascript" src="_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
        <script type="text/javascript" src="_static/jquery.js"></script>
        <script type="text/javascript" src="_static/underscore.js"></script>
        <script type="text/javascript" src="_static/doctools.js"></script>
        <script type="text/javascript" src="_static/language_data.js"></script>
    
    <script type="text/javascript" src="_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Helmert Coding" href="helmert.html" />
    <link rel="prev" title="Generalized Linear Mixed Model Encoder" href="glmm.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="index.html" class="icon icon-home"> Category Encoders
          

          
          </a>

          
            
            
              <div class="version">
                latest
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="backward_difference.html">Backward Difference Coding</a></li>
<li class="toctree-l1"><a class="reference internal" href="basen.html">BaseN</a></li>
<li class="toctree-l1"><a class="reference internal" href="binary.html">Binary</a></li>
<li class="toctree-l1"><a class="reference internal" href="catboost.html">CatBoost Encoder</a></li>
<li class="toctree-l1"><a class="reference internal" href="glmm.html">Generalized Linear Mixed Model Encoder</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Hashing</a></li>
<li class="toctree-l1"><a class="reference internal" href="helmert.html">Helmert Coding</a></li>
<li class="toctree-l1"><a class="reference internal" href="jamesstein.html">James-Stein Encoder</a></li>
<li class="toctree-l1"><a class="reference internal" href="leaveoneout.html">Leave One Out</a></li>
<li class="toctree-l1"><a class="reference internal" href="mestimate.html">M-estimate</a></li>
<li class="toctree-l1"><a class="reference internal" href="onehot.html">One Hot</a></li>
<li class="toctree-l1"><a class="reference internal" href="ordinal.html">Ordinal</a></li>
<li class="toctree-l1"><a class="reference internal" href="polynomial.html">Polynomial Coding</a></li>
<li class="toctree-l1"><a class="reference internal" href="sum.html">Sum Coding</a></li>
<li class="toctree-l1"><a class="reference internal" href="targetencoder.html">Target Encoder</a></li>
<li class="toctree-l1"><a class="reference internal" href="woe.html">Weight of Evidence</a></li>
<li class="toctree-l1"><a class="reference internal" href="wrapper.html">Wrappers</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">Category Encoders</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="index.html">Docs</a> &raquo;</li>
        
      <li>Hashing</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="_sources/hashing.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="hashing">
<h1>Hashing<a class="headerlink" href="#hashing" title="Permalink to this headline">¶</a></h1>
<dl class="class">
<dt id="category_encoders.hashing.HashingEncoder">
<em class="property">class </em><code class="sig-prename descclassname">category_encoders.hashing.</code><code class="sig-name descname">HashingEncoder</code><span class="sig-paren">(</span><em class="sig-param">max_process=0</em>, <em class="sig-param">max_sample=0</em>, <em class="sig-param">verbose=0</em>, <em class="sig-param">n_components=8</em>, <em class="sig-param">cols=None</em>, <em class="sig-param">drop_invariant=False</em>, <em class="sig-param">return_df=True</em>, <em class="sig-param">hash_method='md5'</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/category_encoders/hashing.html#HashingEncoder"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#category_encoders.hashing.HashingEncoder" title="Permalink to this definition">¶</a></dt>
<dd><p>A multivariate hashing implementation with configurable dimensionality/precision.</p>
<p>The advantage of this encoder is that it does not maintain a dictionary of observed categories.
Consequently, the encoder does not grow in size and accepts new values during data scoring
by design.</p>
<p>It’s important to read about how max_process &amp; max_sample work
before setting them manually, inappropriate setting slows down encoding.</p>
<p>Default value of ‘max_process’ is 1 on Windows because multiprocessing might cause issues, see in :
<a class="reference external" href="https://github.com/scikit-learn-contrib/categorical-encoding/issues/215">https://github.com/scikit-learn-contrib/categorical-encoding/issues/215</a>
<a class="reference external" href="https://docs.python.org/2/library/multiprocessing.html?highlight=process#windows">https://docs.python.org/2/library/multiprocessing.html?highlight=process#windows</a></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>verbose: int</strong></dt><dd><p>integer indicating verbosity of the output. 0 for none.</p>
</dd>
<dt><strong>cols: list</strong></dt><dd><p>a list of columns to encode, if None, all string columns will be encoded.</p>
</dd>
<dt><strong>drop_invariant: bool</strong></dt><dd><p>boolean for whether or not to drop columns with 0 variance.</p>
</dd>
<dt><strong>return_df: bool</strong></dt><dd><p>boolean for whether to return a pandas DataFrame from transform (otherwise it will be a numpy array).</p>
</dd>
<dt><strong>hash_method: str</strong></dt><dd><p>which hashing method to use. Any method from hashlib works.</p>
</dd>
<dt><strong>max_process: int</strong></dt><dd><p>how many processes to use in transform(). Limited in range(1, 64).
By default, it uses half of the logical CPUs.
For example, 4C4T makes max_process=2, 4C8T makes max_process=4.
Set it larger if you have a strong CPU.
It is not recommended to set it larger than is the count of the
logical CPUs as it will actually slow down the encoding.</p>
</dd>
<dt><strong>max_sample: int</strong></dt><dd><p>how many samples to encode by each process at a time.
This setting is useful on low memory machines.
By default, max_sample=(all samples num)/(max_process).
For example, 4C8T CPU with 100,000 samples makes max_sample=25,000,
6C12T CPU with 100,000 samples makes max_sample=16,666.
It is not recommended to set it larger than the default value.</p>
</dd>
<dt><strong>n_components: int</strong></dt><dd><p>how many bits to use to represent the feature. By default we use 8 bits.
For high-cardinality features, consider using up-to 32 bits.</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">References</p>
<dl class="citation">
<dt class="label" id="r8dde675226a2-1"><span class="brackets">R8dde675226a2-1</span></dt>
<dd><p>Feature Hashing for Large Scale Multitask Learning, from</p>
</dd>
</dl>
<p><a class="reference external" href="https://alex.smola.org/papers/2009/Weinbergeretal09.pdf">https://alex.smola.org/papers/2009/Weinbergeretal09.pdf</a>
.. [R8dde675226a2-2] Don’t be tricked by the Hashing Trick, from
<a class="reference external" href="https://booking.ai/dont-be-tricked-by-the-hashing-trick-192a6aae3087">https://booking.ai/dont-be-tricked-by-the-hashing-trick-192a6aae3087</a></p>
<p class="rubric">Methods</p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#category_encoders.hashing.HashingEncoder.fit" title="category_encoders.hashing.HashingEncoder.fit"><code class="xref py py-obj docutils literal notranslate"><span class="pre">fit</span></code></a>(self, X[, y])</p></td>
<td><p>Fit encoder according to X and y.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">fit_transform</span></code>(self, X[, y])</p></td>
<td><p>Fit to data, then transform it.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#category_encoders.hashing.HashingEncoder.get_feature_names" title="category_encoders.hashing.HashingEncoder.get_feature_names"><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_feature_names</span></code></a>(self)</p></td>
<td><p>Returns the names of all transformed / added columns.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_params</span></code>(self[, deep])</p></td>
<td><p>Get parameters for this estimator.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#category_encoders.hashing.HashingEncoder.hashing_trick" title="category_encoders.hashing.HashingEncoder.hashing_trick"><code class="xref py py-obj docutils literal notranslate"><span class="pre">hashing_trick</span></code></a>(X_in[, hashing_method, N, …])</p></td>
<td><p>A basic hashing implementation with configurable dimensionality/precision</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">set_params</span></code>(self, \*\*params)</p></td>
<td><p>Set the parameters of this estimator.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#category_encoders.hashing.HashingEncoder.transform" title="category_encoders.hashing.HashingEncoder.transform"><code class="xref py py-obj docutils literal notranslate"><span class="pre">transform</span></code></a>(self, X[, override_return_df])</p></td>
<td><p>Call _transform() if you want to use single CPU with all samples</p></td>
</tr>
</tbody>
</table>
<table class="docutils align-default">
<colgroup>
<col style="width: 62%" />
<col style="width: 38%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><strong>require_data</strong></p></td>
<td></td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="category_encoders.hashing.HashingEncoder.fit">
<code class="sig-name descname">fit</code><span class="sig-paren">(</span><em class="sig-param">self</em>, <em class="sig-param">X</em>, <em class="sig-param">y=None</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/category_encoders/hashing.html#HashingEncoder.fit"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#category_encoders.hashing.HashingEncoder.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit encoder according to X and y.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>X</strong><span class="classifier">array-like, shape = [n_samples, n_features]</span></dt><dd><p>Training vectors, where n_samples is the number of samples
and n_features is the number of features.</p>
</dd>
<dt><strong>y</strong><span class="classifier">array-like, shape = [n_samples]</span></dt><dd><p>Target values.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt><strong>self</strong><span class="classifier">encoder</span></dt><dd><p>Returns self.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="category_encoders.hashing.HashingEncoder.get_feature_names">
<code class="sig-name descname">get_feature_names</code><span class="sig-paren">(</span><em class="sig-param">self</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/category_encoders/hashing.html#HashingEncoder.get_feature_names"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#category_encoders.hashing.HashingEncoder.get_feature_names" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the names of all transformed / added columns.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><dl class="simple">
<dt>feature_names: list</dt><dd><p>A list with all feature names transformed or added.
Note: potentially dropped features are not included!</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="category_encoders.hashing.HashingEncoder.hashing_trick">
<em class="property">static </em><code class="sig-name descname">hashing_trick</code><span class="sig-paren">(</span><em class="sig-param">X_in</em>, <em class="sig-param">hashing_method='md5'</em>, <em class="sig-param">N=2</em>, <em class="sig-param">cols=None</em>, <em class="sig-param">make_copy=False</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/category_encoders/hashing.html#HashingEncoder.hashing_trick"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#category_encoders.hashing.HashingEncoder.hashing_trick" title="Permalink to this definition">¶</a></dt>
<dd><p>A basic hashing implementation with configurable dimensionality/precision</p>
<p>Performs the hashing trick on a pandas dataframe, <cite>X</cite>, using the hashing method from hashlib
identified by <cite>hashing_method</cite>.  The number of output dimensions (<cite>N</cite>), and columns to hash (<cite>cols</cite>) are
also configurable.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>X_in: pandas dataframe</strong></dt><dd><p>description text</p>
</dd>
<dt><strong>hashing_method: string, optional</strong></dt><dd><p>description text</p>
</dd>
<dt><strong>N: int, optional</strong></dt><dd><p>description text</p>
</dd>
<dt><strong>cols: list, optional</strong></dt><dd><p>description text</p>
</dd>
<dt><strong>make_copy: bool, optional</strong></dt><dd><p>description text</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt><strong>out</strong><span class="classifier">dataframe</span></dt><dd><p>A hashing encoded dataframe.</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">References</p>
<p>Cite the relevant literature, e.g. <span id="id3">[R6b702480991a-1]</span>.  You may also cite these
references in the notes section above.
.. [R6b702480991a-1] Kilian Weinberger; Anirban Dasgupta; John Langford; Alex Smola; Josh Attenberg (2009). Feature Hashing
for Large Scale Multitask Learning. Proc. ICML.</p>
</dd></dl>

<dl class="method">
<dt id="category_encoders.hashing.HashingEncoder.transform">
<code class="sig-name descname">transform</code><span class="sig-paren">(</span><em class="sig-param">self</em>, <em class="sig-param">X</em>, <em class="sig-param">override_return_df=False</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/category_encoders/hashing.html#HashingEncoder.transform"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#category_encoders.hashing.HashingEncoder.transform" title="Permalink to this definition">¶</a></dt>
<dd><p>Call _transform() if you want to use single CPU with all samples</p>
</dd></dl>

</dd></dl>

</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="helmert.html" class="btn btn-neutral float-right" title="Helmert Coding" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="glmm.html" class="btn btn-neutral float-left" title="Generalized Linear Mixed Model Encoder" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2016, Will McGinnis

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>